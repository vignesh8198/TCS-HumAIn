{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Number_Plate_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh8198/TCS-HumAIn/blob/master/Number_Plate_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGEv5PZ8dHx4",
        "colab_type": "text"
      },
      "source": [
        "Number Plate Detection and Optical Character Recognition(OCR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ6ba3afZVVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#installs the modules to the instance to be able to interpret images; may take a while to complete\n",
        "assume_max_lv_gear = True\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install opencv-python\n",
        "from PIL import Image\n",
        "from pytesseract import image_to_string\n",
        "import pytesseract\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "import os, re, time,cv2\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "from pytesseract import image_to_string\n",
        "import pytesseract\n",
        "\n",
        "from glob import glob\n",
        "from string import ascii_lowercase, digits\n",
        "\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "#2.uploading files from google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "#Write Json file\n",
        "with io.open('numberplate.json', 'w', encoding='utf8') as outfile:\n",
        "    str_ = json.dumps(data,\n",
        "                      indent=4, sort_keys=True,\n",
        "                      separators=(',', ': '), ensure_ascii=False)\n",
        "    outfile.write(to_unicode(str_))\n",
        " \n",
        "#Read JSON file\n",
        "with open('numberplate.json') as data_file:\n",
        "    data_loaded = json.load(data_file)\n",
        "\n",
        "print(data == data_loaded)\n",
        "\n",
        "\n",
        "del data['extras']\n",
        "\n",
        "# Extract the points of the bounding boxes because thats what we want\n",
        "data['points'] = data.apply(lambda row: row['annotation'][0]['points'], axis=1)\n",
        "\n",
        "# And drop the rest of the annotation info\n",
        "del data['annotation']\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "        # Get the image from the URL\n",
        "        resp = urllib.request.urlopen(row[0])\n",
        "        im = np.array(Image.open(resp))\n",
        "\n",
        "        # We append the image to the training input array\n",
        "        Images.append(im)  \n",
        "\n",
        "        # Points of rectangle\n",
        "        x_point_top = row[1][0]['x']*im.shape[1]\n",
        "        y_point_top = row[1][0]['y']*im.shape[0]\n",
        "        x_point_bot = row[1][1]['x']*im.shape[1]\n",
        "        y_point_bot = row[1][1]['y']*im.shape[0]\n",
        "\n",
        "        # Cut the plate from the image and use it as output\n",
        "        carImage = Image.fromarray(im)\n",
        "        plateImage = carImage.crop((x_point_top, y_point_top, x_point_bot, y_point_bot))\n",
        "        Plates.append(np.array(plateImage))\n",
        "\n",
        "\n",
        "ax[0].set_title('Input Image')\n",
        "ax[1].set_title('Output Image')\n",
        "\n",
        "# Display the images\n",
        "ax[0].imshow(Images[0])\n",
        "ax[1].imshow(Plates[0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#The following function reads an uploaded image file from Cloud Storage and calls a function to detect whether the image contains text:\n",
        "\n",
        "def process_image(file, context):\n",
        "    \"\"\"Cloud Function triggered by Cloud Storage when a file is changed.\n",
        "    Args:\n",
        "        file (dict): Metadata of the changed file, provided by the triggering\n",
        "                                 Cloud Storage event.\n",
        "        context (google.cloud.functions.Context): Metadata of triggering event.\n",
        "    \n",
        "    \"\"\"\n",
        "    bucket = validate_message(file, 'bucket')\n",
        "    name = validate_message(file, 'name')\n",
        "\n",
        "    detect_text(bucket, name)\n",
        "\n",
        "    print('File {} processed.'.format(file['name']))\n",
        "\n",
        "\n",
        "#defines functions used to filter out noise information and parse image into text\n",
        "\n",
        "def process(k,img):\n",
        "    if  k == 'plus' or k == 'level':\n",
        "        #since level and plus are read off the picture of the gear, there is a lot of noise\n",
        "        #so we need an iterative process to do it\n",
        "        thresh = cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU\n",
        "        low = 81\n",
        "        proc = cv2.cvtColor(cv2.medianBlur(cv2.threshold(cv2.cvtColor(cv2.resize(img, (0, 0), fx=5, fy=5), cv2.COLOR_RGB2GRAY), low, 255, thresh)[1], 3), cv2.COLOR_GRAY2RGB)\n",
        "        data = image_to_string(Image.fromarray(proc), lang='eng', config='--psm 7').replace('+b','6').replace('>','0')\n",
        "        if not any(i.isdigit() for i in data):\n",
        "            low = 100\n",
        "            proc = cv2.cvtColor(cv2.medianBlur(cv2.threshold(cv2.cvtColor(cv2.resize(img, (0, 0), fx=5, fy=5), cv2.COLOR_RGB2GRAY), low, 255, thresh)[1], 3), cv2.COLOR_GRAY2RGB)\n",
        "            data = image_to_string(Image.fromarray(proc), lang='eng', config='--psm 7').replace('+b','6').replace('>','0')\n",
        "            if not any(i.isdigit() for i in data):\n",
        "                low = 125\n",
        "                proc = cv2.cvtColor(cv2.medianBlur(cv2.threshold(cv2.cvtColor(cv2.resize(img, (0, 0), fx=5, fy=5), cv2.COLOR_RGB2GRAY), low, 255, thresh)[1], 3), cv2.COLOR_GRAY2RGB)\n",
        "                data = image_to_string(Image.fromarray(proc), lang='eng', config='--psm 7').replace('+b','6').replace('>','0')\n",
        "                if not any(i.isdigit() for i in data): data = str(0)\n",
        "                  \n",
        "    else:\n",
        "        thresh = cv2.THRESH_BINARY_INV\n",
        "        low = 70\n",
        "        proc = cv2.cvtColor(cv2.medianBlur(cv2.threshold(cv2.cvtColor(cv2.resize(img, (0, 0), fx=5, fy=5), cv2.COLOR_BGR2GRAY), low, 255, thresh)[1], 3), cv2.COLOR_GRAY2RGB)\n",
        "        data = image_to_string(Image.fromarray(proc), lang='eng', config='--psm 6').replace('Rina','Ring').replace('Edic','Epic').replace('Enic','Epic')\n",
        "    return data\n",
        "\n",
        "def stat_converter(stat):\n",
        "    result = ''\n",
        "    if 'attack' in stat.lower():\n",
        "        result = 'Atk'\n",
        "        if '%' in stat: result += 'P'\n",
        "    if 'health' in stat.lower():\n",
        "        result = 'HP'\n",
        "        if '%' in stat: result += 'P'\n",
        "    if 'defense' in stat.lower():\n",
        "        result = 'Def'\n",
        "        if '%' in stat: result += 'P'\n",
        "    if 'speed' in stat.lower(): result = 'Spd'\n",
        "    if 'chance' in stat.lower(): result = 'CChance'\n",
        "    if 'damage' in stat.lower(): result = 'CDmg'\n",
        "    if 'effectiveness' in stat.lower(): result = 'Eff'\n",
        "    if 'resistance' in stat.lower(): result = 'Res'\n",
        "    return result\n",
        "  \n",
        "\n",
        "def digit_filter(val):\n",
        "    if not val: \n",
        "        return 0\n",
        "    if val is '.':\n",
        "        return 0\n",
        "    else:\n",
        "        return int(''.join(filter(str.isdigit,val)))\n",
        "\n",
        "def char_filter(val):\n",
        "    return ''.join(filter(str.isalpha,val)).capitalize()\n",
        "  \n",
        "\n",
        "Training Dataset\n",
        "\n",
        "def read_label(tf_bytestring):\n",
        "    label = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
        "    dataset = dataset.prefetch(-1)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "  \n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    return dataset\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_fil\n",
        "\n",
        "# This model trains to 99.4% accuracy in 10 epochs (with a batch size of 64)  \n",
        "\n",
        "def make_model():\n",
        "    model = tf.keras.Sequential(\n",
        "      [\n",
        "        tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1), name=\"image\"),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=12, kernel_size=3, padding='same', use_bias=False), # no bias necessary before batch norm\n",
        "        tf.keras.layers.BatchNormalization(scale=False, center=True), # no batch norm scaling necessary before \"relu\"\n",
        "        tf.keras.layers.Activation('relu'), # activation after batch norm\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=24, kernel_size=6, padding='same', use_bias=False, strides=2),\n",
        "        tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=32, kernel_size=6, padding='same', use_bias=False, strides=2),\n",
        "        tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(200, use_bias=False),\n",
        "        tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.Dropout(0.4), # Dropout on dense layer only\n",
        "\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "      ])\n",
        "\n",
        "    model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "with strategy.scope():\n",
        "    model = make_model()\n",
        "\n",
        "# print model layers\n",
        "model.summary()\n",
        "\n",
        "# set up learning rate decay\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
        "    verbose=True)  \n",
        "\n",
        "#fit the model \n",
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)\n",
        "\n",
        "#evaluate on unseen data\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))  \n",
        "\n",
        "#Visualize Predictions\n",
        "\n",
        "# recognize digits from number plate\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)\n",
        "                                            \n",
        "                                            \n",
        "                                            \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}